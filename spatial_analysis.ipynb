{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1u20N2QEv0swECj9eG9spCAjM-cugCodn",
      "authorship_tag": "ABX9TyNocZmphX/PGTSghFHRuW7r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ombuijabali/spatial_analysis/blob/main/spatial_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "oVph0enBK0Nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rasterstats"
      ],
      "metadata": {
        "id": "k_wUPRhVnIli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import rasterio\n",
        "from rasterstats import zonal_stats\n",
        "import fiona\n",
        "import os"
      ],
      "metadata": {
        "id": "OaYxFRj7m6zC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading settelement boundary and adding a unique identifier"
      ],
      "metadata": {
        "id": "kTNRkpjOmlf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the settlement polygons shapefile\n",
        "settlements_path = '/content/drive/MyDrive/ML/spatial analysis/boundary/settelements.shp'\n",
        "settlements_gdf = gpd.read_file(settlements_path)\n",
        "\n",
        "# Add a new column 'settlement_id' with unique identifiers for each settlement\n",
        "settlements_gdf['settlement_id'] = range(1, len(settlements_gdf) + 1)\n",
        "\n",
        "# Save the GeoDataFrame back to the shapefile\n",
        "settlements_gdf.to_file('/content/drive/MyDrive/ML/spatial analysis/boundary/settelements_with_id.shp')\n"
      ],
      "metadata": {
        "id": "Q9o76jOwm4qK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARKNeGOrJ-P1"
      },
      "outputs": [],
      "source": [
        "#Data Extraction for Education, Healthcare, Public Service and Business Centers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read the unique classes in the data downloaded"
      ],
      "metadata": {
        "id": "46Nn7MADaQiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the pois polygon shapefile\n",
        "input_shapefile_path = '/content/drive/MyDrive/ML/spatial analysis/landuse/gis_osm_pois_a_free_1.shp'\n",
        "\n",
        "# Read the shapefile using geopandas\n",
        "gdf = gpd.read_file(input_shapefile_path)\n",
        "\n",
        "# Display the unique values in the \"fclass\" field\n",
        "unique_classes = gdf['fclass'].unique()\n",
        "\n",
        "# Print the unique classes\n",
        "print(\"Unique Classes in the 'fclass' field:\")\n",
        "for fclass in unique_classes:\n",
        "    print(fclass)"
      ],
      "metadata": {
        "id": "_G3xEwHMKQAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract the necessary classes to new shapefiles"
      ],
      "metadata": {
        "id": "zwhBB5nCaUHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the original shapefile\n",
        "gdf = gpd.read_file(input_shapefile_path)\n",
        "\n",
        "# Define the classes to extract\n",
        "classes_to_extract = {\n",
        "    'Education': ['school', 'college', 'university'],\n",
        "    'Healthcare': ['hospital', 'pharmacy', 'clinic', 'doctors'],\n",
        "    'Commercial': ['hotel', 'bank', 'supermarket', 'market_place'],\n",
        "    'PublicServices': ['police', 'community_centre', 'library', 'fire_station']\n",
        "}\n",
        "\n",
        "# Create a new GeoDataFrame for each class and save to a new shapefile\n",
        "for category, class_list in classes_to_extract.items():\n",
        "    filtered_gdf = gdf[gdf['fclass'].isin(class_list)]\n",
        "\n",
        "    if not filtered_gdf.empty:\n",
        "        # Path for the new shapefile\n",
        "        output_shapefile_path = f'/content/drive/MyDrive/ML/spatial analysis/results/{category}_shapefile.shp'\n",
        "\n",
        "        # Save the filtered GeoDataFrame to a new shapefile\n",
        "        filtered_gdf.to_file(output_shapefile_path)\n",
        "        print(f\"{category} Shapefile saved to {output_shapefile_path}\")\n",
        "    else:\n",
        "        print(f\"No features found for {category}\")\n"
      ],
      "metadata": {
        "id": "ZQ28Qcl1KQGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyzing Population data for each settelement"
      ],
      "metadata": {
        "id": "UiKR9isaKlQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the population raster file\n",
        "population_raster_path = '/content/drive/MyDrive/ML/spatial analysis/population/lbr_general_2020.tif'\n",
        "\n",
        "# Path to the settlement polygons shapefile\n",
        "settlements_path = '/content/drive/MyDrive/ML/spatial analysis/boundary/settelements_with_id.shp'\n",
        "\n",
        "# Read the population raster using rasterio\n",
        "with rasterio.open(population_raster_path) as population_raster:\n",
        "    population_data = population_raster.read(1)\n",
        "    transform = population_raster.transform\n",
        "\n",
        "# Read the settlement polygons\n",
        "settlements_gdf = gpd.read_file(settlements_path)\n",
        "\n",
        "# Function to calculate zonal statistics (population sum)\n",
        "def calculate_population_sum(polygon, population_data, transform):\n",
        "    # Extract population sum using zonal_stats\n",
        "    population_stats = zonal_stats(polygon.geometry, population_data, affine=transform, stats=['sum'])\n",
        "    population_sum = population_stats[0]['sum']\n",
        "\n",
        "    return pd.Series({'Population_Sum': population_sum})\n",
        "\n",
        "# Apply the function to each settlement polygon\n",
        "settlements_with_population_sum = settlements_gdf.apply(\n",
        "    lambda row: calculate_population_sum(row, population_data, transform),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Merge the results back to the original GeoDataFrame\n",
        "settlements_with_population_sum = pd.concat([settlements_gdf, settlements_with_population_sum], axis=1)\n",
        "\n",
        "# Save the GeoDataFrame with population sum information to a new shapefile\n",
        "output_shapefile_path = '/content/drive/MyDrive/ML/spatial analysis/results/settlements_with_population_sum.shp'\n",
        "settlements_with_population_sum.to_file(output_shapefile_path)"
      ],
      "metadata": {
        "id": "ckiCsZdIhg_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the number of buildings, schools, hosipital, markets for each settelement"
      ],
      "metadata": {
        "id": "lyRWZq1vZ12r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load school shapefile\n",
        "schools = gpd.read_file('/content/drive/MyDrive/ML/spatial analysis/eductational/Education_shapefile.shp')\n",
        "\n",
        "# Load hospital shapefile\n",
        "hospitals = gpd.read_file('/content/drive/MyDrive/ML/spatial analysis/healthcare/Healthcare_shapefile.shp')\n",
        "\n",
        "# Load public facilities shapefile\n",
        "public_facilities = gpd.read_file('/content/drive/MyDrive/ML/spatial analysis/public_service/PublicServices_shapefile.shp')\n",
        "\n",
        "# Load market shapefile\n",
        "markets = gpd.read_file('/content/drive/MyDrive/ML/spatial analysis/commercial/Commercial_shapefile.shp')\n",
        "\n",
        "# Load buildings shapefile\n",
        "buildings = gpd.read_file('/content/drive/MyDrive/ML/spatial analysis/buildings/gis_osm_buildings_a_free_1.shp')\n",
        "\n",
        "# Load boundary shapefile\n",
        "boundaries = gpd.read_file('/content/drive/MyDrive/ML/spatial analysis/results/settlements_with_population_sum.shp')\n",
        "\n",
        "# Perform spatial join for each type of facility\n",
        "schools_within_boundaries = gpd.sjoin(schools, boundaries, how='inner', op='within')\n",
        "hospitals_within_boundaries = gpd.sjoin(hospitals, boundaries, how='inner', op='within')\n",
        "public_facilities_within_boundaries = gpd.sjoin(public_facilities, boundaries, how='inner', op='within')\n",
        "markets_within_boundaries = gpd.sjoin(markets, boundaries, how='inner', op='within')\n",
        "buildings_within_boundaries = gpd.sjoin(buildings, boundaries, how='inner', op='within')\n",
        "\n",
        "# Group by boundary and count the number of facilities within each boundary\n",
        "school_counts = schools_within_boundaries.groupby('index_right').size().reset_index(name='school_count')\n",
        "hospital_counts = hospitals_within_boundaries.groupby('index_right').size().reset_index(name='hospital_count')\n",
        "public_facilities_counts = public_facilities_within_boundaries.groupby('index_right').size().reset_index(name='public_count')\n",
        "market_counts = markets_within_boundaries.groupby('index_right').size().reset_index(name='market_count')\n",
        "buildings_counts = buildings_within_boundaries.groupby('index_right').size().reset_index(name='building_count')\n",
        "\n",
        "# Merge the results back to the boundaries GeoDataFrame\n",
        "boundaries_with_counts = boundaries.merge(school_counts, left_index=True, right_on='index_right', how='left')\n",
        "boundaries_with_counts = boundaries_with_counts.merge(hospital_counts, left_on='index_right', right_on='index_right', how='left')\n",
        "boundaries_with_counts = boundaries_with_counts.merge(public_facilities_counts, left_on='index_right', right_on='index_right', how='left')\n",
        "boundaries_with_counts = boundaries_with_counts.merge(market_counts, left_on='index_right', right_on='index_right', how='left')\n",
        "boundaries_with_counts = boundaries_with_counts.merge(buildings_counts, left_on='index_right', right_on='index_right', how='left')\n",
        "\n",
        "# Fill NaN values (no facilities) with 0\n",
        "boundaries_with_counts[['school_count', 'hospital_count', 'public_count', 'market_count', 'building_count']] = \\\n",
        "    boundaries_with_counts[['school_count', 'hospital_count', 'public_count', 'market_count', 'building_count']].fillna(0)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "boundaries_with_counts.drop(['index_right'], axis=1, inplace=True)\n",
        "\n",
        "# Save the result to a new shapefile\n",
        "boundaries_with_counts.to_file('/content/drive/MyDrive/ML/spatial analysis/results/settlements_with_facility_count.shp', driver='ESRI Shapefile')"
      ],
      "metadata": {
        "id": "4uJRDYuA6oo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the distance between settelement and grid infrastructre"
      ],
      "metadata": {
        "id": "NH2hv2uyZjPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Install dependicies\n",
        "pip install osmnx\n"
      ],
      "metadata": {
        "id": "ZSSZydWnBMW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import osmnx as ox\n",
        "import networkx as nx\n",
        "from shapely.geometry import LineString\n",
        "\n",
        "# Load the boundary shapefile\n",
        "boundary = gpd.read_file('/content/drive/MyDrive/ML/spatial analysis/results/output11_shapefile.shp')\n",
        "\n",
        "# Load the point shapefiles (power plants, power towers, substations)\n",
        "power_plants = gpd.read_file('/content/drive/MyDrive/ML/spatial analysis/grid_infra/Liberia_PowerPlant.shp')\n",
        "power_towers = gpd.read_file('/content/drive/MyDrive/ML/spatial analysis/grid_infra/Liberia_Powertower_withDEM.shp')\n",
        "substations = gpd.read_file('/content/drive/MyDrive/ML/spatial analysis/grid_infra/Liberia_Substation.shp')\n",
        "\n",
        "# Download road network graph for Liberia using osmnx\n",
        "G = ox.graph_from_place('Liberia', network_type='drive')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_GHVx35k3s7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to find the nearest node on the road network\n",
        "def find_nearest_node(geometry, graph):\n",
        "    if geometry.geom_type == 'Point':\n",
        "        x, y = geometry.x, geometry.y\n",
        "    elif geometry.geom_type == 'Polygon':\n",
        "        x, y = geometry.centroid.x, geometry.centroid.y\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported geometry type. Expected Point or Polygon.\")\n",
        "\n",
        "    node, distance = min(graph.nodes(data=True), key=lambda n: ((n[1]['x'] - x) ** 2 + (n[1]['y'] - y) ** 2) ** 0.5)\n",
        "    return node, distance\n",
        "\n",
        "\n",
        "# Function to calculate shortest distance for each point type\n",
        "def calculate_shortest_distances(boundary_df, point_type, point_df):\n",
        "    for b_idx, boundary_point in boundary_df.iterrows():\n",
        "        # Find the nearest road network node for the boundary point\n",
        "        nearest_node, boundary_distance = find_nearest_node(boundary_point.geometry, G)\n",
        "\n",
        "        # Initialize variables to store the nearest point and its distance\n",
        "        nearest_point, nearest_distance = None, float('inf')\n",
        "\n",
        "        for p_idx, point in point_df.iterrows():\n",
        "            # Find the nearest road network node for the target point\n",
        "            target_node, distance = find_nearest_node(point.geometry, G)\n",
        "\n",
        "            # Calculate shortest path length\n",
        "            path_length = nx.shortest_path_length(G, source=nearest_node, target=target_node, weight='length')\n",
        "\n",
        "            # Update nearest point if a shorter distance is found\n",
        "            if path_length < nearest_distance:\n",
        "                nearest_point, nearest_distance = point_type, path_length\n",
        "\n",
        "        # Add the distance to the attribute table of the boundary shapefile\n",
        "        boundary_df.at[b_idx, f'shortest_distance_to_{nearest_point}'] = nearest_distance\n",
        "\n",
        "# Calculate shortest distances for each boundary point\n",
        "calculate_shortest_paths(boundary, 'power_plants', power_plants)\n",
        "calculate_shortest_paths(boundary, 'power_towers', power_towers)\n",
        "calculate_shortest_paths(boundary, 'substations', substations)\n",
        "\n",
        "# Save the updated boundary shapefile\n",
        "boundary.to_file('/content/drive/MyDrive/ML/spatial analysis/results/settlement_shapefile_with_distances.shp')\n"
      ],
      "metadata": {
        "id": "NN8UQGzkDDLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a network of te extracted paths."
      ],
      "metadata": {
        "id": "l5RuFecC33ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty GeoDataFrame to store the connecting lines\n",
        "lines_gdf = gpd.GeoDataFrame(columns=['geometry', 'point_type', 'distance'])\n",
        "\n",
        "# Function to calculate and store connecting lines\n",
        "def calculate_connecting_lines(boundary_df, point_type, point_df):\n",
        "    global lines_gdf  # Declare lines_gdf as global\n",
        "\n",
        "    for b_idx, boundary_point in boundary_df.iterrows():\n",
        "        # Find the nearest road network node for the boundary point\n",
        "        nearest_node, boundary_distance = find_nearest_node(boundary_point.geometry, G)\n",
        "\n",
        "        # Initialize variables to store the nearest point and its distance\n",
        "        nearest_point, nearest_distance = None, float('inf')\n",
        "\n",
        "        for p_idx, point in point_df.iterrows():\n",
        "            # Find the nearest road network node for the target point\n",
        "            target_node, distance = find_nearest_node(point.geometry, G)\n",
        "\n",
        "            # Calculate shortest path\n",
        "            path = nx.shortest_path(G, source=nearest_node, target=target_node, weight='length')\n",
        "\n",
        "            # Convert the path to a LineString\n",
        "            line = LineString([(G.nodes[node]['x'], G.nodes[node]['y']) for node in path])\n",
        "\n",
        "            # Add the connecting line to the GeoDataFrame\n",
        "            lines_gdf = lines_gdf.append({'geometry': line, 'point_type': point_type, 'distance': len(path)},\n",
        "                                         ignore_index=True)\n",
        "\n",
        "# Calculate connecting lines for each boundary point\n",
        "calculate_connecting_lines(boundary, 'power_plants', power_plants)\n",
        "calculate_connecting_lines(boundary, 'power_towers', power_towers)\n",
        "calculate_connecting_lines(boundary, 'substations', substations)\n",
        "\n",
        "# Save the GeoDataFrame with connecting lines to a new shapefile\n",
        "lines_gdf.to_file('/content/drive/MyDrive/ML/spatial analysis/results/settlement_lines_shapefile.shp')\n"
      ],
      "metadata": {
        "id": "6T42o0OXT5RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Additional data i.e Relative wealth index, soil/geology and landuse"
      ],
      "metadata": {
        "id": "K_mS-jhhJ8cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Relative Wealth Index"
      ],
      "metadata": {
        "id": "IHugflzSZeT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load rwi shapefile\n",
        "rwi = gpd.read_file('/content/drive/MyDrive/ML/spatial analysis/rwi.shp')\n",
        "\n",
        "# Load boundary shapefile\n",
        "boundaries = gpd.read_file('/content/drive/MyDrive/ML/spatial analysis/distance_to_grid_infra.shp')\n",
        "\n",
        "# Spatial join without common column names\n",
        "rwi_within_boundaries = gpd.sjoin(rwi, boundaries, how='inner', op='within')\n",
        "\n",
        "# Group by boundary and count the number of schools within each boundary\n",
        "boundary_counts = rwi_within_boundaries.groupby('index_right').size().reset_index(name='rwi')\n",
        "\n",
        "# Merge the result back to the boundaries GeoDataFrame\n",
        "boundaries_with_rwi_counts = boundaries.merge(boundary_counts, left_index=True, right_on='index_right', how='left')\n",
        "\n",
        "# Fill NaN values (no rwi) with 0\n",
        "boundaries_with_rwi_counts['rwi'].fillna(0, inplace=True)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "boundaries_with_rwi_counts.drop(['index_right'], axis=1, inplace=True)\n",
        "\n",
        "# Display the result\n",
        "print(boundaries_with_rwi_counts)\n",
        "\n",
        "# Save the result to a new shapefile\n",
        "boundaries_with_rwi_counts.to_file('/content/drive/MyDrive/ML/spatial analysis/results/output13_shapefile.shp', driver='ESRI Shapefile')\n"
      ],
      "metadata": {
        "id": "Sg1wCigBDbub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LandUse"
      ],
      "metadata": {
        "id": "W-9tWl6ZZbj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the land use shapefile\n",
        "land_use = gpd.read_file('/content/drive/MyDrive/ML/spatial analysis/landuse/gis_osm_landuse_a_free_1.shp')\n",
        "\n",
        "# Load the boundary shapefile\n",
        "boundary = gpd.read_file('/content/drive/MyDrive/ML/spatial analysis/results/output13_shapefile.shp')\n",
        "\n",
        "# Perform spatial join\n",
        "joined_data = gpd.sjoin(boundary, land_use, how=\"left\", op=\"intersects\")\n",
        "\n",
        "# Reset the index of joined_data\n",
        "joined_data = joined_data.reset_index(drop=True)\n",
        "\n",
        "# Append the landuse column to the boundary shapefile\n",
        "boundary['landuse'] = joined_data['fclass']\n",
        "\n",
        "# Save the result to a new shapefile\n",
        "boundary.to_file('/content/drive/MyDrive/ML/spatial analysis/results/boundary_land_use.shp')\n"
      ],
      "metadata": {
        "id": "4RXfmeMFDbxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Soil and Geology"
      ],
      "metadata": {
        "id": "MfyKGnVDDb0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the soil shapefile\n",
        "soil = gpd.read_file('/content/drive/MyDrive/ML/spatial analysis/soil/soil.shp')\n",
        "\n",
        "# Load the boundary shapefile\n",
        "boundary = gpd.read_file('/content/drive/MyDrive/ML/spatial analysis/results/boundary_land_use.shp')\n",
        "\n",
        "# Perform spatial join\n",
        "joined_data = gpd.sjoin(boundary, soil, how=\"left\", op=\"intersects\")\n",
        "\n",
        "# Reset the index of joined_data\n",
        "joined_data = joined_data.reset_index(drop=True)\n",
        "\n",
        "# Append the soil column to the boundary shapefile\n",
        "boundary['soil_type'] = joined_data['DOMSOI']\n",
        "\n",
        "# Save the result to a new shapefile\n",
        "boundary.to_file('/content/drive/MyDrive/ML/spatial analysis/results/boundary_soil_geology.shp')\n"
      ],
      "metadata": {
        "id": "DBgxrYz8Db26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualization of results"
      ],
      "metadata": {
        "id": "3TFfmbWGDb8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Read the dataframe of final shapefile."
      ],
      "metadata": {
        "id": "c5u8kMwMDb_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "\n",
        "# Path to the final shapefile\n",
        "final_shapefile_path = '/content/drive/MyDrive/ML/spatial analysis/boundary_soil_geology.shp'\n",
        "\n",
        "# Read the GeoDataFrame from the shapefile\n",
        "final_gdf = gpd.read_file(final_shapefile_path)\n",
        "\n",
        "# Display the GeoDataFrame\n",
        "print(final_gdf.head())\n"
      ],
      "metadata": {
        "id": "gxf7HpbcvTlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Pie charts and a bar chart"
      ],
      "metadata": {
        "id": "qOLoHhwDvTpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install plotly geopandas\n"
      ],
      "metadata": {
        "id": "faOoPVVEnL1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the shapefile\n",
        "shapefile_path = '/content/drive/MyDrive/ML/spatial analysis/boundary_soil_geology.shp'\n",
        "gdf = gpd.read_file(shapefile_path)\n",
        "\n",
        "# Plot the bar chart\n",
        "gdf.plot(kind='bar', x='settlement', y='school_cou', legend=False)\n",
        "plt.xlabel('Settlements')\n",
        "plt.ylabel('Number of Schools')\n",
        "plt.title('Number of Schools in Each Settlement')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Plot pie chart for 'landuse'\n",
        "landuse_counts = gdf['landuse'].value_counts()\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.pie(landuse_counts, labels=landuse_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "plt.title('Land Use Distribution')\n",
        "plt.show()\n",
        "\n",
        "# Plot pie chart for 'soil_type'\n",
        "soil_type_counts = gdf['soil_type'].value_counts()\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.pie(soil_type_counts, labels=soil_type_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "plt.title('Soil Type Distribution')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "QJkAf0zCvTtP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}